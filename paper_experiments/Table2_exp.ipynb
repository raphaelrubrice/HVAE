{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "906dba2b",
   "metadata": {},
   "source": [
    "# **Reproducing M1 results (Table 2)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75a8ff9",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/blackswan-advitamaeternam/HVAE/blob/raph/paper_experiments/Table2_exp.ipynb\"> <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0870c4",
   "metadata": {},
   "source": [
    "## **Colab setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bdaeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "# to avoid having the data on your drive\n",
    "%cd /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8161172",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/blackswan-advitamaeternam/HVAE.git\n",
    "%cd HVAE\n",
    "!git checkout raph\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607ff11a",
   "metadata": {},
   "source": [
    "To allow automatic reloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c69c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371091e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "try:\n",
    "    import imp\n",
    "except ImportError:\n",
    "    import types\n",
    "    sys.modules['imp'] = types.ModuleType('imp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2aa07cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fbf981",
   "metadata": {},
   "source": [
    "## **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad80071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "# To ensure the custom package is found\n",
    "path_to_repo = \"/content/HVAE\"\n",
    "if path_to_repo not in sys.path:\n",
    "    sys.path.append(path_to_repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5289a43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from svae.vae import M1, predict_classes_loader\n",
    "from svae.training import training_M1\n",
    "from svae.utils import ShuffledLoader\n",
    "\n",
    "from paper_experiments.load_MNIST import make_splits_loaders_MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc53309",
   "metadata": {},
   "source": [
    "Setting device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597a74bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94e13b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make splits\n",
    "NUM_WORKERS = int(0.8*os.cpu_count())\n",
    "FRAC = 0.1\n",
    "TRAIN_FRAC = int(50000 * FRAC)\n",
    "VAL_FRAC = int(10000 * FRAC)\n",
    "TEST_FRAC = None # potentially still test on all test samples\n",
    "print(f\"Using {NUM_WORKERS} workers.\")\n",
    "train_loader, val_loader, test_loader = make_splits_loaders_MNIST(train_size=TRAIN_FRAC, val_size=VAL_FRAC, test_size=TEST_FRAC,\n",
    "                                                                batch_size=64,\n",
    "                                                                test_batch_size=100,\n",
    "                                                                num_workers=NUM_WORKERS,\n",
    "                                                                prefetch_factor=2,\n",
    "                                                                force=True,\n",
    "                                                                persistent_workers=True,\n",
    "                                                                pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3699bd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manifesting to memory of the device (we can afford it on colab ?)\n",
    "train_batches = [[el.to(DEVICE) for el in batch] for batch in train_loader]\n",
    "val_batches   = [[el.to(DEVICE) for el in batch] for batch in val_loader]\n",
    "test_batches  = [[el.to(DEVICE) for el in batch] for batch in test_loader]\n",
    "\n",
    "# Wrap for shuffling behavior\n",
    "train_loader = ShuffledLoader(\n",
    "    train_batches,\n",
    "    shuffle_batches=True,\n",
    "    shuffle_within_batch=True,\n",
    "    device_for_randperm=DEVICE)\n",
    "\n",
    "val_loader = val_batches\n",
    "test_loader = test_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d79c317",
   "metadata": {},
   "source": [
    "## **Configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4871cea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/content/drive/MyDrive/HVAE/Table2/\"\n",
    "os.makedirs(base_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c37ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 500\n",
    "INPUT_DIM = 784\n",
    "HIDDEN_DIM = 128\n",
    "\n",
    "LATENT_MODE = 'sample'\n",
    "PATIENCE = 50\n",
    "WARMUP = 100\n",
    "ONE_LAYER = False\n",
    "LR = 1e-3\n",
    "\n",
    "N_RUNS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac119da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_and_test(mode, latent, test_dataloader):\n",
    "    addon = \"[SVAE]\" if mode == \"svae\" else \"[NVAE]\"\n",
    "\n",
    "    print(f\"\\n{addon} Instantiating SVAE and optimizer..\")\n",
    "    model = M1(mode,\n",
    "                INPUT_DIM,\n",
    "                HIDDEN_DIM,\n",
    "                latent,\n",
    "                ONE_LAYER,\n",
    "                )\n",
    "    # To device\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "    print(f\"{addon} Started training..\")\n",
    "    model, losses, all_parts = training_M1(train_loader, \n",
    "                                    val_loader,\n",
    "                                    model,\n",
    "                                    optimizer,\n",
    "                                    epochs=EPOCHS,\n",
    "                                    beta_kl=1,\n",
    "                                    warmup=WARMUP,\n",
    "                                    patience=PATIENCE,\n",
    "                                    show_loss_every=1,\n",
    "                                    mode=LATENT_MODE)\n",
    "\n",
    "    print(f\"\\n{addon} Predicting classes..\")\n",
    "    Y, Y_hat = predict_classes_loader(model, test_dataloader, LATENT_MODE)\n",
    "\n",
    "    test_acc = accuracy_score(Y, Y_hat)\n",
    "    print(f\"{addon} Test accuracy: {test_acc*100:.2f}\")\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436cfef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch_experiment(N, test_dataloader):\n",
    "    results_df = {\"Latent Size\":[], \"Model\":[], \"Accuracy\":[], \"Std\":[], \"N_test\":[]}\n",
    "    for latent in tqdm([2, 5, 10, 20, 40], desc=\"Exploring latent..\"):\n",
    "        for mode in [\"svae\", \"normal\"]:\n",
    "            accuracy_list = []\n",
    "            for i in tqdm(list(range(N_RUNS)), desc=\"Repeated runs..\"):\n",
    "                print(f\"\\nSTARTING RUN nÂ°{i+1}\")\n",
    "                accuracy_list.append(run_and_test(mode, latent, test_dataloader))\n",
    "            avg_acc = np.nanmean(accuracy_list)\n",
    "            std_acc = np.nanstd(accuracy_list)\n",
    "\n",
    "            results_df[\"Latent Size\"].append(latent)\n",
    "            results_df[\"Model\"].append(mode)\n",
    "            results_df[\"Accuracy\"].append(avg_acc)\n",
    "            results_df[\"Std\"].append(std_acc)\n",
    "            results_df[\"N_test\"].append(N)\n",
    "    return pd.DataFrame(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8e34b3",
   "metadata": {},
   "source": [
    "## **$N = 100$**\n",
    "Test Batch size is 100 so only test on 1 batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568a8657",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_test_loader = [batch for i, batch in enumerate(test_loader) if i < 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b34efaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_100 = launch_experiment(100, sub_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34b52fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_100.to_csv(base_path + \"100_M1_results.csv\")\n",
    "results_df_100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8430d247",
   "metadata": {},
   "source": [
    "## **$N = 600$**\n",
    "Test Batch size is 100 so only test on 6 batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c59363",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_test_loader = [batch for i, batch in enumerate(test_loader) if i < 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d16e3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_600 = launch_experiment(600, sub_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47309a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_600.to_csv(base_path + \"600_M1_results.csv\")\n",
    "results_df_600"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159fd0d3",
   "metadata": {},
   "source": [
    "## **$N = 1000$**\n",
    "only test on 10 batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbc3668",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_test_loader = [batch for i, batch in enumerate(test_loader) if i < 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfb242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_1000 = launch_experiment(1000, sub_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee78a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_1000.to_csv(base_path + \"1000_M1_results.csv\")\n",
    "results_df_1000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
